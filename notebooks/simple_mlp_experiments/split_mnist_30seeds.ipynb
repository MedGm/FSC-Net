{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41c4102e",
   "metadata": {},
   "source": [
    "# Split-MNIST: 30-Seed Run with Simple MLP\n",
    "\n",
    "## üéØ Goal: Robust Statistics for Paper\n",
    "\n",
    "**Context**: Ablation study showed NN1-Simple (89.1%) > NN1-Similarity (87.9%)\n",
    "\n",
    "**This Experiment**:\n",
    "- Run 30 independent seeds for robust statistics\n",
    "- Report mean ¬± std for retention accuracy\n",
    "- Statistical significance testing\n",
    "- Compare to baseline (no consolidation)\n",
    "\n",
    "**Expected Results**:\n",
    "- Mean retention: ~89% (matching ablation)\n",
    "- Std dev: ~1.5%\n",
    "- Significant improvement over baseline\n",
    "\n",
    "**Timeline**: ~4 days to complete\n",
    "\n",
    "---\n",
    "\n",
    "**Date**: November 9, 2025  \n",
    "**Priority**: CRITICAL (needed for paper revision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0a0eea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üñ•Ô∏è  Device: cpu\n",
      "üìÖ 2025-11-09 17:10:26\n",
      "üî• PyTorch: 2.9.0+cu128\n",
      "\n",
      "‚≠ê‚≠ê‚≠ê CRITICAL: 30-Seed Split-MNIST Experiment ‚≠ê‚≠ê‚≠ê\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/medgm/vsc/FSSGNET/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "from scipy import stats\n",
    "\n",
    "from src.models import (\n",
    "    NN1_SimpleMLP,\n",
    "    NN2_ConsolidationNet,\n",
    "    ReplayBuffer,\n",
    "    evaluate_models,\n",
    "    train_task_with_replay,\n",
    "    consolidate_nn2\n",
    ")\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"üñ•Ô∏è  Device: {device}\")\n",
    "print(f\"üìÖ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"üî• PyTorch: {torch.__version__}\")\n",
    "print(\"\\n‚≠ê‚≠ê‚≠ê CRITICAL: 30-Seed Split-MNIST Experiment ‚≠ê‚≠ê‚≠ê\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219a4b10",
   "metadata": {},
   "source": [
    "## 1. Load Split-MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17de5597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Split-MNIST Created:\n",
      "   Task 1: Digits 0-1: 12665 train samples\n",
      "   Task 2: Digits 2-3: 12089 train samples\n",
      "   Task 3: Digits 4-5: 11263 train samples\n",
      "   Task 4: Digits 6-7: 12183 train samples\n",
      "   Task 5: Digits 8-9: 11800 train samples\n"
     ]
    }
   ],
   "source": [
    "# Download MNIST\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST('../../data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('../../data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Split into 5 tasks (2 digits each)\n",
    "def create_task_split(dataset, digit_pairs):\n",
    "    \"\"\"Create dataset subset for specific digit pairs\"\"\"\n",
    "    indices = []\n",
    "    for idx, (img, label) in enumerate(dataset):\n",
    "        if label in digit_pairs:\n",
    "            indices.append(idx)\n",
    "    return Subset(dataset, indices)\n",
    "\n",
    "tasks = [\n",
    "    ([0, 1], \"Task 1: Digits 0-1\"),\n",
    "    ([2, 3], \"Task 2: Digits 2-3\"),\n",
    "    ([4, 5], \"Task 3: Digits 4-5\"),\n",
    "    ([6, 7], \"Task 4: Digits 6-7\"),\n",
    "    ([8, 9], \"Task 5: Digits 8-9\"),\n",
    "]\n",
    "\n",
    "train_tasks = [create_task_split(train_dataset, digits) for digits, _ in tasks]\n",
    "test_tasks = [create_task_split(test_dataset, digits) for digits, _ in tasks]\n",
    "\n",
    "print(\"‚úÖ Split-MNIST Created:\")\n",
    "for i, ((digits, name), train_task) in enumerate(zip(tasks, train_tasks)):\n",
    "    print(f\"   {name}: {len(train_task)} train samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87471812",
   "metadata": {},
   "source": [
    "## 2. Single-Seed Experiment Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ebe205",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_single_seed(seed, verbose=False):\n",
    "    \"\"\"\n",
    "    Run one complete continual learning experiment\n",
    "    \n",
    "    Returns:\n",
    "        dict with final retention accuracies for NN1 and NN2\n",
    "    \"\"\"\n",
    "    # Set seed\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    \n",
    "    # Initialize models\n",
    "    nn1 = NN1_SimpleMLP(\n",
    "        in_dim=784,\n",
    "        neuron_dim=64,\n",
    "        num_classes=10\n",
    "    ).to(device)\n",
    "    \n",
    "    nn2 = NN2_ConsolidationNet(\n",
    "        in_dim=784,\n",
    "        summary_dim=64,\n",
    "        num_classes=10\n",
    "    ).to(device)\n",
    "    \n",
    "    # Optimizers\n",
    "    opt1 = torch.optim.Adam(nn1.parameters(), lr=1e-3)\n",
    "    opt2 = torch.optim.Adam(nn2.parameters(), lr=5e-4)\n",
    "    \n",
    "    # Loss functions\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    kl_loss = nn.KLDivLoss(reduction='batchmean')\n",
    "    \n",
    "    # Replay buffer\n",
    "    replay_buffer = ReplayBuffer(buffer_size_per_task=200)\n",
    "    \n",
    "    # Track results\n",
    "    results = {\n",
    "        'nn1_retention': [],  # Retention on all previous tasks\n",
    "        'nn2_retention': [],\n",
    "    }\n",
    "    \n",
    "    # Hyperparameters\n",
    "    batch_size = 64\n",
    "    epochs_per_task = 5\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"üå± Seed {seed}\")\n",
    "        print(f\"{'='*60}\")\n",
    "    \n",
    "    # Train on each task sequentially\n",
    "    for task_id, (train_task, test_task) in enumerate(zip(train_tasks, test_tasks)):\n",
    "        if verbose:\n",
    "            print(f\"\\nüìö {tasks[task_id][1]}\")\n",
    "        \n",
    "        # Create data loaders\n",
    "        train_loader = DataLoader(train_task, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        # Train with replay\n",
    "        train_task_with_replay(\n",
    "            nn1, nn2,\n",
    "            train_loader,\n",
    "            replay_buffer.get_dataset(),\n",
    "            opt1, opt2,\n",
    "            ce_loss, kl_loss,\n",
    "            device=device,\n",
    "            epochs=epochs_per_task,\n",
    "            consolidation_interval=10,\n",
    "            lambda_distill=0.3,\n",
    "            temperature=2.0,\n",
    "            grad_clip=1.0,\n",
    "            replay_ratio=0.3\n",
    "        )\n",
    "        \n",
    "        # Add to replay buffer\n",
    "        replay_buffer.add_task(train_task)\n",
    "        \n",
    "        # Consolidate NN2\n",
    "        consolidate_nn2(\n",
    "            nn1, nn2,\n",
    "            replay_buffer.get_dataset(),\n",
    "            opt2,\n",
    "            ce_loss, kl_loss,\n",
    "            device=device,\n",
    "            consolidation_epochs=2,\n",
    "            batch_size=64,\n",
    "            lambda_distill=0.5,\n",
    "            temperature=2.0,\n",
    "            grad_clip=1.0\n",
    "        )\n",
    "        \n",
    "        # Evaluate retention on ALL tasks seen so far\n",
    "        if task_id >= 1:  # After task 2+\n",
    "            all_test_data = []\n",
    "            for prev_task_id in range(task_id + 1):\n",
    "                all_test_data.extend(test_tasks[prev_task_id])\n",
    "            \n",
    "            test_loader = DataLoader(all_test_data, batch_size=128, shuffle=False)\n",
    "            acc1, acc2 = evaluate_models(nn1, nn2, test_loader, device=device)\n",
    "            \n",
    "            results['nn1_retention'].append(acc1 * 100)\n",
    "            results['nn2_retention'].append(acc2 * 100)\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"   üìä Retention (Tasks 1-{task_id+1}): NN1={acc1*100:.1f}%, NN2={acc2*100:.1f}%\")\n",
    "    \n",
    "    # Return final retention (after task 5)\n",
    "    return {\n",
    "        'seed': seed,\n",
    "        'nn1_final': results['nn1_retention'][-1],\n",
    "        'nn2_final': results['nn2_retention'][-1],\n",
    "        'nn1_all': results['nn1_retention'],\n",
    "        'nn2_all': results['nn2_retention'],\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ Experiment function ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557dfb1c",
   "metadata": {},
   "source": [
    "## 3. Test with Single Seed (Sanity Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3cadb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test with one seed\n",
    "print(\"üß™ Testing with seed 42...\")\n",
    "test_result = run_single_seed(42, verbose=True)\n",
    "\n",
    "print(f\"\\n‚úÖ Test Complete!\")\n",
    "print(f\"   Final NN1 retention: {test_result['nn1_final']:.2f}%\")\n",
    "print(f\"   Final NN2 retention: {test_result['nn2_final']:.2f}%\")\n",
    "print(f\"\\n   Expected: ~89% (matching ablation study)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb18c66b",
   "metadata": {},
   "source": [
    "## 4. Run 30 Seeds (CRITICAL EXPERIMENT)\n",
    "\n",
    "‚ö†Ô∏è **WARNING**: This will take ~4 days to complete!\n",
    "\n",
    "**Timeline**:\n",
    "- ~8 minutes per seed (5 tasks √ó 5 epochs √ó ~20s)\n",
    "- 30 seeds √ó 8 min = 240 minutes = 4 hours (if sequential)\n",
    "- With overhead: ~6-8 hours total\n",
    "\n",
    "**Note**: If running on CPU, this could take much longer. Consider:\n",
    "1. Using GPU if available\n",
    "2. Running seeds in parallel (if multiple GPUs)\n",
    "3. Running overnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a5bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 30 seeds\n",
    "NUM_SEEDS = 30\n",
    "seeds = list(range(42, 42 + NUM_SEEDS))  # Seeds 42-71\n",
    "\n",
    "print(f\"üöÄ Starting 30-seed run...\")\n",
    "print(f\"   Seeds: {seeds[0]} to {seeds[-1]}\")\n",
    "print(f\"   Estimated time: 4-8 hours\\n\")\n",
    "\n",
    "all_results = []\n",
    "\n",
    "for i, seed in enumerate(tqdm(seeds, desc=\"Seeds\")):\n",
    "    result = run_single_seed(seed, verbose=False)\n",
    "    all_results.append(result)\n",
    "    \n",
    "    # Save intermediate results every 5 seeds\n",
    "    if (i + 1) % 5 == 0:\n",
    "        df_temp = pd.DataFrame(all_results)\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        df_temp.to_csv(f\"../../results/simple_mlp/csv/split_mnist_30seeds_partial_{i+1}_{timestamp}.csv\", index=False)\n",
    "        print(f\"   üíæ Saved partial results ({i+1}/{NUM_SEEDS} seeds)\")\n",
    "\n",
    "print(\"\\n‚úÖ 30-seed run complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e53fff4a",
   "metadata": {},
   "source": [
    "## 5. Statistical Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb76a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df_results = pd.DataFrame(all_results)\n",
    "\n",
    "# Summary statistics\n",
    "print(\"üìä RESULTS SUMMARY (30 Seeds)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nNN1 Final Retention (After Task 5):\")\n",
    "print(f\"   Mean: {df_results['nn1_final'].mean():.2f}%\")\n",
    "print(f\"   Std:  {df_results['nn1_final'].std():.2f}%\")\n",
    "print(f\"   Min:  {df_results['nn1_final'].min():.2f}%\")\n",
    "print(f\"   Max:  {df_results['nn1_final'].max():.2f}%\")\n",
    "\n",
    "print(f\"\\nNN2 Final Retention (After Task 5):\")\n",
    "print(f\"   Mean: {df_results['nn2_final'].mean():.2f}%\")\n",
    "print(f\"   Std:  {df_results['nn2_final'].std():.2f}%\")\n",
    "print(f\"   Min:  {df_results['nn2_final'].min():.2f}%\")\n",
    "print(f\"   Max:  {df_results['nn2_final'].max():.2f}%\")\n",
    "\n",
    "# Confidence intervals (95%)\n",
    "nn1_ci = stats.t.interval(0.95, len(df_results)-1, \n",
    "                          loc=df_results['nn1_final'].mean(),\n",
    "                          scale=stats.sem(df_results['nn1_final']))\n",
    "nn2_ci = stats.t.interval(0.95, len(df_results)-1,\n",
    "                          loc=df_results['nn2_final'].mean(),\n",
    "                          scale=stats.sem(df_results['nn2_final']))\n",
    "\n",
    "print(f\"\\n95% Confidence Intervals:\")\n",
    "print(f\"   NN1: [{nn1_ci[0]:.2f}%, {nn1_ci[1]:.2f}%]\")\n",
    "print(f\"   NN2: [{nn2_ci[0]:.2f}%, {nn2_ci[1]:.2f}%]\")\n",
    "\n",
    "# Save full results\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "csv_path = f\"../../results/simple_mlp/csv/split_mnist_30seeds_final_{timestamp}.csv\"\n",
    "df_results.to_csv(csv_path, index=False)\n",
    "print(f\"\\nüíæ Results saved: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8f91be",
   "metadata": {},
   "source": [
    "## 6. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bca0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Plot 1: Distribution of final retention\n",
    "ax = axes[0, 0]\n",
    "ax.hist(df_results['nn1_final'], bins=15, alpha=0.7, label='NN1', color='steelblue', edgecolor='black')\n",
    "ax.hist(df_results['nn2_final'], bins=15, alpha=0.7, label='NN2', color='coral', edgecolor='black')\n",
    "ax.axvline(df_results['nn1_final'].mean(), color='steelblue', linestyle='--', linewidth=2)\n",
    "ax.axvline(df_results['nn2_final'].mean(), color='coral', linestyle='--', linewidth=2)\n",
    "ax.set_xlabel('Final Retention (%)', fontsize=12)\n",
    "ax.set_ylabel('Frequency', fontsize=12)\n",
    "ax.set_title('Distribution of Final Retention (30 Seeds)', fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Retention across tasks\n",
    "ax = axes[0, 1]\n",
    "task_labels = ['T2', 'T3', 'T4', 'T5']\n",
    "nn1_means = [np.mean([r['nn1_all'][i] for r in all_results]) for i in range(4)]\n",
    "nn2_means = [np.mean([r['nn2_all'][i] for r in all_results]) for i in range(4)]\n",
    "nn1_stds = [np.std([r['nn1_all'][i] for r in all_results]) for i in range(4)]\n",
    "nn2_stds = [np.std([r['nn2_all'][i] for r in all_results]) for i in range(4)]\n",
    "\n",
    "x = np.arange(len(task_labels))\n",
    "ax.errorbar(x, nn1_means, yerr=nn1_stds, marker='o', capsize=5, capthick=2, \n",
    "            linewidth=2, markersize=8, label='NN1 (Simple MLP)', color='steelblue')\n",
    "ax.errorbar(x, nn2_means, yerr=nn2_stds, marker='s', capsize=5, capthick=2,\n",
    "            linewidth=2, markersize=8, label='NN2 (Consolidation)', color='coral')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(task_labels)\n",
    "ax.set_xlabel('After Task', fontsize=12)\n",
    "ax.set_ylabel('Retention Accuracy (%)', fontsize=12)\n",
    "ax.set_title('Retention Across Tasks (Mean ¬± Std)', fontsize=13, fontweight='bold')\n",
    "ax.legend(fontsize=11)\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.set_ylim([75, 100])\n",
    "\n",
    "# Plot 3: Box plot comparison\n",
    "ax = axes[1, 0]\n",
    "data_to_plot = [df_results['nn1_final'], df_results['nn2_final']]\n",
    "bp = ax.boxplot(data_to_plot, labels=['NN1', 'NN2'], patch_artist=True,\n",
    "                boxprops=dict(facecolor='lightblue', edgecolor='black'),\n",
    "                medianprops=dict(color='red', linewidth=2),\n",
    "                whiskerprops=dict(color='black'),\n",
    "                capprops=dict(color='black'))\n",
    "ax.set_ylabel('Final Retention (%)', fontsize=12)\n",
    "ax.set_title('Box Plot: Final Retention Distribution', fontsize=13, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# Plot 4: Summary statistics table\n",
    "ax = axes[1, 1]\n",
    "ax.axis('off')\n",
    "summary_text = f\"\"\"\n",
    "30-SEED SPLIT-MNIST RESULTS\n",
    "{'='*40}\n",
    "\n",
    "NN1 (Simple MLP) Final Retention:\n",
    "  Mean:  {df_results['nn1_final'].mean():.2f}%\n",
    "  Std:   {df_results['nn1_final'].std():.2f}%\n",
    "  95% CI: [{nn1_ci[0]:.2f}%, {nn1_ci[1]:.2f}%]\n",
    "\n",
    "NN2 (Consolidation) Final Retention:\n",
    "  Mean:  {df_results['nn2_final'].mean():.2f}%\n",
    "  Std:   {df_results['nn2_final'].std():.2f}%\n",
    "  95% CI: [{nn2_ci[0]:.2f}%, {nn2_ci[1]:.2f}%]\n",
    "\n",
    "Comparison to Ablation Study:\n",
    "  Ablation (1 seed):  89.1%\n",
    "  This (30 seeds):    {df_results['nn1_final'].mean():.2f}% ¬± {df_results['nn1_final'].std():.2f}%\n",
    "  \n",
    "Status: {'‚úÖ VALIDATED' if abs(df_results['nn1_final'].mean() - 89.1) < 2 else '‚ö†Ô∏è INVESTIGATE'}\n",
    "\"\"\"\n",
    "ax.text(0.1, 0.5, summary_text, fontsize=11, family='monospace',\n",
    "        verticalalignment='center', bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.3))\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_path = f\"../../results/simple_mlp/figures/split_mnist_30seeds_{timestamp}.png\"\n",
    "plt.savefig(fig_path, dpi=300, bbox_inches='tight')\n",
    "print(f\"üíæ Figure saved: {fig_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474d7230",
   "metadata": {},
   "source": [
    "## 7. Statistical Significance vs Baseline\n",
    "\n",
    "Compare to a baseline without consolidation (NN1 only, no NN2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b224be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For paper: we need to show our method significantly outperforms baseline\n",
    "# The baseline would be using NN1 without NN2 consolidation\n",
    "# We can estimate this from the NN1-only results (which degrade faster)\n",
    "\n",
    "# If you have baseline results, add them here for t-test comparison\n",
    "# For now, we'll note the NN1 vs NN2 improvement\n",
    "\n",
    "improvement = df_results['nn2_final'].mean() - df_results['nn1_final'].mean()\n",
    "t_stat, p_value = stats.ttest_rel(df_results['nn2_final'], df_results['nn1_final'])\n",
    "\n",
    "print(\"\\nüìà NN2 vs NN1 Comparison:\")\n",
    "print(f\"   Improvement: {improvement:+.2f}%\")\n",
    "print(f\"   t-statistic: {t_stat:.3f}\")\n",
    "print(f\"   p-value: {p_value:.6f}\")\n",
    "print(f\"   Significance: {'‚úÖ Significant (p<0.05)' if p_value < 0.05 else '‚ö†Ô∏è Not significant'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéâ EXPERIMENT COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nKey Findings:\")\n",
    "print(f\"  ‚Ä¢ Simple MLP retention: {df_results['nn1_final'].mean():.2f}% ¬± {df_results['nn1_final'].std():.2f}%\")\n",
    "print(f\"  ‚Ä¢ Consolidation retention: {df_results['nn2_final'].mean():.2f}% ¬± {df_results['nn2_final'].std():.2f}%\")\n",
    "print(f\"  ‚Ä¢ Matches ablation finding: {'‚úÖ YES' if abs(df_results['nn1_final'].mean() - 89.1) < 2 else '‚ö†Ô∏è NO'}\")\n",
    "print(f\"\\nNext Steps:\")\n",
    "print(f\"  1. Update paper with these robust statistics\")\n",
    "print(f\"  2. Run CIFAR-10 validation experiment\")\n",
    "print(f\"  3. Update rebuttal with statistical analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
